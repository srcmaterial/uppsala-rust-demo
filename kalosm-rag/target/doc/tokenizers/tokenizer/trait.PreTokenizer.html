<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="The `PreTokenizer` is in charge of doing the pre-segmentation step. It splits the given string in multiple substrings, keeping track of the offsets of said substrings from the `NormalizedString`. In some occasions, the `PreTokenizer` might need to modify the given `NormalizedString` to ensure we can entirely keep track of the offsets and the mapping with the original string."><title>PreTokenizer in tokenizers::tokenizer - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../static.files/rustdoc-916cea96.css"><meta name="rustdoc-vars" data-root-path="../../" data-static-root-path="../../static.files/" data-current-crate="tokenizers" data-themes="" data-resource-suffix="" data-rustdoc-version="1.87.0 (17067e9ac 2025-05-09)" data-channel="1.87.0" data-search-js="search-e7298875.js" data-settings-js="settings-d72f25bb.js" ><script src="../../static.files/storage-82c7156e.js"></script><script defer src="sidebar-items.js"></script><script defer src="../../static.files/main-fb8c74a8.js"></script><noscript><link rel="stylesheet" href="../../static.files/noscript-893ab5e7.css"></noscript><link rel="icon" href="https://huggingface.co/favicon.ico"></head><body class="rustdoc trait"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button><a class="logo-container" href="../../tokenizers/index.html"><img src="https://huggingface.co/landing/assets/huggingface_logo.svg" alt=""></a></nav><nav class="sidebar"><div class="sidebar-crate"><a class="logo-container" href="../../tokenizers/index.html"><img src="https://huggingface.co/landing/assets/huggingface_logo.svg" alt="logo"></a><h2><a href="../../tokenizers/index.html">tokenizers</a><span class="version">0.21.1</span></h2></div><div class="sidebar-elems"><section id="rustdoc-toc"><h2 class="location"><a href="#">PreTokenizer</a></h2><h3><a href="#required-methods">Required Methods</a></h3><ul class="block"><li><a href="#tymethod.pre_tokenize" title="pre_tokenize">pre_tokenize</a></li></ul><h3><a href="#implementors">Implementors</a></h3></section><div id="rustdoc-modnav"><h2><a href="index.html">In tokenizers::<wbr>tokenizer</a></h2></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><div class="rustdoc-breadcrumbs"><a href="../index.html">tokenizers</a>::<wbr><a href="index.html">tokenizer</a></div><h1>Trait <span class="trait">PreTokenizer</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../../src/tokenizers/tokenizer/mod.rs.html#65-67">Source</a> </span></div><pre class="rust item-decl"><code>pub trait PreTokenizer {
    // Required method
    fn <a href="#tymethod.pre_tokenize" class="fn">pre_tokenize</a>(&amp;self, pretokenized: &amp;mut <a class="struct" href="pre_tokenizer/struct.PreTokenizedString.html" title="struct tokenizers::tokenizer::pre_tokenizer::PreTokenizedString">PreTokenizedString</a>) -&gt; <a class="type" href="type.Result.html" title="type tokenizers::tokenizer::Result">Result</a>&lt;<a class="primitive" href="https://doc.rust-lang.org/1.87.0/std/primitive.unit.html">()</a>&gt;;
}</code></pre><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>The <code>PreTokenizer</code> is in charge of doing the pre-segmentation step. It splits the given string
in multiple substrings, keeping track of the offsets of said substrings from the
<code>NormalizedString</code>. In some occasions, the <code>PreTokenizer</code> might need to modify the given
<code>NormalizedString</code> to ensure we can entirely keep track of the offsets and the mapping with
the original string.</p>
</div></details><h2 id="required-methods" class="section-header">Required Methods<a href="#required-methods" class="anchor">§</a></h2><div class="methods"><section id="tymethod.pre_tokenize" class="method"><a class="src rightside" href="../../src/tokenizers/tokenizer/mod.rs.html#66">Source</a><h4 class="code-header">fn <a href="#tymethod.pre_tokenize" class="fn">pre_tokenize</a>(&amp;self, pretokenized: &amp;mut <a class="struct" href="pre_tokenizer/struct.PreTokenizedString.html" title="struct tokenizers::tokenizer::pre_tokenizer::PreTokenizedString">PreTokenizedString</a>) -&gt; <a class="type" href="type.Result.html" title="type tokenizers::tokenizer::Result">Result</a>&lt;<a class="primitive" href="https://doc.rust-lang.org/1.87.0/std/primitive.unit.html">()</a>&gt;</h4></section></div><h2 id="implementors" class="section-header">Implementors<a href="#implementors" class="anchor">§</a></h2><div id="implementors-list"><section id="impl-PreTokenizer-for-PreTokenizerWrapper" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/mod.rs.html#42-58">Source</a><a href="#impl-PreTokenizer-for-PreTokenizerWrapper" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="enum" href="../pre_tokenizers/enum.PreTokenizerWrapper.html" title="enum tokenizers::pre_tokenizers::PreTokenizerWrapper">PreTokenizerWrapper</a></h3></section><section id="impl-PreTokenizer-for-BertPreTokenizer" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/bert.rs.html#13-18">Source</a><a href="#impl-PreTokenizer-for-BertPreTokenizer" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/bert/struct.BertPreTokenizer.html" title="struct tokenizers::pre_tokenizers::bert::BertPreTokenizer">BertPreTokenizer</a></h3></section><section id="impl-PreTokenizer-for-ByteLevel" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/byte_level.rs.html#120-152">Source</a><a href="#impl-PreTokenizer-for-ByteLevel" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/byte_level/struct.ByteLevel.html" title="struct tokenizers::pre_tokenizers::byte_level::ByteLevel">ByteLevel</a></h3><div class="docblock"><p>As a <code>PreTokenizer</code>, <code>ByteLevel</code> is in charge of transforming all the unicode characters into
their byte-level counterpart. It also splits the input according to the configured regex.</p>
</div></section><section id="impl-PreTokenizer-for-CharDelimiterSplit" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/delimiter.rs.html#19-26">Source</a><a href="#impl-PreTokenizer-for-CharDelimiterSplit" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/delimiter/struct.CharDelimiterSplit.html" title="struct tokenizers::pre_tokenizers::delimiter::CharDelimiterSplit">CharDelimiterSplit</a></h3></section><section id="impl-PreTokenizer-for-Digits" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/digits.rs.html#27-39">Source</a><a href="#impl-PreTokenizer-for-Digits" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/digits/struct.Digits.html" title="struct tokenizers::pre_tokenizers::digits::Digits">Digits</a></h3></section><section id="impl-PreTokenizer-for-Metaspace" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/metaspace.rs.html#116-142">Source</a><a href="#impl-PreTokenizer-for-Metaspace" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/metaspace/struct.Metaspace.html" title="struct tokenizers::pre_tokenizers::metaspace::Metaspace">Metaspace</a></h3></section><section id="impl-PreTokenizer-for-Punctuation" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/punctuation.rs.html#34-38">Source</a><a href="#impl-PreTokenizer-for-Punctuation" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/punctuation/struct.Punctuation.html" title="struct tokenizers::pre_tokenizers::punctuation::Punctuation">Punctuation</a></h3></section><section id="impl-PreTokenizer-for-Sequence" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/sequence.rs.html#26-33">Source</a><a href="#impl-PreTokenizer-for-Sequence" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/sequence/struct.Sequence.html" title="struct tokenizers::pre_tokenizers::sequence::Sequence">Sequence</a></h3></section><section id="impl-PreTokenizer-for-Split" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/split.rs.html#96-104">Source</a><a href="#impl-PreTokenizer-for-Split" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/split/struct.Split.html" title="struct tokenizers::pre_tokenizers::split::Split">Split</a></h3></section><section id="impl-PreTokenizer-for-UnicodeScripts" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/unicode_scripts/pre_tokenizer.rs.html#40-77">Source</a><a href="#impl-PreTokenizer-for-UnicodeScripts" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/unicode_scripts/struct.UnicodeScripts.html" title="struct tokenizers::pre_tokenizers::unicode_scripts::UnicodeScripts">UnicodeScripts</a></h3></section><section id="impl-PreTokenizer-for-Whitespace" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/whitespace.rs.html#18-29">Source</a><a href="#impl-PreTokenizer-for-Whitespace" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/whitespace/struct.Whitespace.html" title="struct tokenizers::pre_tokenizers::whitespace::Whitespace">Whitespace</a></h3></section><section id="impl-PreTokenizer-for-WhitespaceSplit" class="impl"><a class="src rightside" href="../../src/tokenizers/pre_tokenizers/whitespace.rs.html#35-41">Source</a><a href="#impl-PreTokenizer-for-WhitespaceSplit" class="anchor">§</a><h3 class="code-header">impl <a class="trait" href="trait.PreTokenizer.html" title="trait tokenizers::tokenizer::PreTokenizer">PreTokenizer</a> for <a class="struct" href="../pre_tokenizers/whitespace/struct.WhitespaceSplit.html" title="struct tokenizers::pre_tokenizers::whitespace::WhitespaceSplit">WhitespaceSplit</a></h3></section></div><script src="../../trait.impl/tokenizers/tokenizer/trait.PreTokenizer.js" async></script></section></div></main></body></html>