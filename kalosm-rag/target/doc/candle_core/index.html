<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="ML framework for Rust"><title>candle_core - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../static.files/rustdoc-916cea96.css"><meta name="rustdoc-vars" data-root-path="../" data-static-root-path="../static.files/" data-current-crate="candle_core" data-themes="" data-resource-suffix="" data-rustdoc-version="1.87.0 (17067e9ac 2025-05-09)" data-channel="1.87.0" data-search-js="search-e7298875.js" data-settings-js="settings-d72f25bb.js" ><script src="../static.files/storage-82c7156e.js"></script><script defer src="../crates.js"></script><script defer src="../static.files/main-fb8c74a8.js"></script><noscript><link rel="stylesheet" href="../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../static.files/favicon-044be391.svg"></head><body class="rustdoc mod crate"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../candle_core/index.html">candle_<wbr>core</a><span class="version">0.8.4</span></h2></div><div class="sidebar-elems"><ul class="block"><li><a id="all-types" href="all.html">All Items</a></li></ul><section id="rustdoc-toc"><h3><a href="#">Sections</a></h3><ul class="block top-toc"><li><a href="#features" title="Features">Features</a></li><li><a href="#faq" title="FAQ">FAQ</a></li><li><a href="#other-crates" title="Other Crates">Other Crates</a></li></ul><h3><a href="#reexports">Crate Items</a></h3><ul class="block"><li><a href="#reexports" title="Re-exports">Re-exports</a></li><li><a href="#modules" title="Modules">Modules</a></li><li><a href="#macros" title="Macros">Macros</a></li><li><a href="#structs" title="Structs">Structs</a></li><li><a href="#enums" title="Enums">Enums</a></li><li><a href="#traits" title="Traits">Traits</a></li></ul></section><div id="rustdoc-modnav"></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><h1>Crate <span>candle_core</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../src/candle_core/lib.rs.html#1-173">Source</a> </span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>ML framework for Rust</p>

<div class="example-wrap"><pre class="rust rust-example-rendered"><code><span class="kw">use </span>candle_core::{Tensor, DType, Device};

<span class="kw">let </span>a = Tensor::arange(<span class="number">0f32</span>, <span class="number">6f32</span>, <span class="kw-2">&amp;</span>Device::Cpu)<span class="question-mark">?</span>.reshape((<span class="number">2</span>, <span class="number">3</span>))<span class="question-mark">?</span>;
<span class="kw">let </span>b = Tensor::arange(<span class="number">0f32</span>, <span class="number">12f32</span>, <span class="kw-2">&amp;</span>Device::Cpu)<span class="question-mark">?</span>.reshape((<span class="number">3</span>, <span class="number">4</span>))<span class="question-mark">?</span>;
<span class="kw">let </span>c = a.matmul(<span class="kw-2">&amp;</span>b)<span class="question-mark">?</span>;
</code></pre></div>
<h3 id="features"><a class="doc-anchor" href="#features">§</a>Features</h3>
<ul>
<li>Simple syntax (looks and feels like PyTorch)</li>
<li>CPU and Cuda backends (and M1 support)</li>
<li>Enable serverless (CPU) small and fast deployments</li>
<li>Model training</li>
<li>Distributed computing (NCCL).</li>
<li>Models out of the box (Llama, Whisper, Falcon, …)</li>
</ul>
<h3 id="faq"><a class="doc-anchor" href="#faq">§</a>FAQ</h3>
<ul>
<li>Why Candle?</li>
</ul>
<p>Candle stems from the need to reduce binary size in order to <em>enable serverless</em>
possible by making the whole engine smaller than PyTorch very large library volume</p>
<p>And simply <em>removing Python</em> from production workloads.
Python can really add overhead in more complex workflows and the <a href="https://www.backblaze.com/blog/the-python-gil-past-present-and-future/">GIL</a> is a notorious source of headaches.</p>
<p>Rust is cool, and a lot of the HF ecosystem already has Rust crates <a href="https://github.com/huggingface/safetensors">safetensors</a> and <a href="https://github.com/huggingface/tokenizers">tokenizers</a></p>
<h3 id="other-crates"><a class="doc-anchor" href="#other-crates">§</a>Other Crates</h3>
<p>Candle consists of a number of crates. This crate holds core the common data structures but you may wish
to look at the docs for the other crates which can be found here:</p>
<ul>
<li><a href="https://docs.rs/candle-core/">candle-core</a>. Core Datastructures and DataTypes.</li>
<li><a href="https://docs.rs/candle-nn/">candle-nn</a>. Building blocks for Neural Nets.</li>
<li><a href="https://docs.rs/candle-datasets/">candle-datasets</a>. Rust access to commonly used Datasets like MNIST.</li>
<li><a href="https://docs.rs/candle-examples/">candle-examples</a>. Examples of Candle in Use.</li>
<li><a href="https://docs.rs/candle-onnx/">candle-onnx</a>. Loading and using ONNX models.</li>
<li><a href="https://docs.rs/candle-pyo3/">candle-pyo3</a>. Access to Candle from Python.</li>
<li><a href="https://docs.rs/candle-transformers/">candle-transformers</a>. Candle implemntation of many published transformer models.</li>
</ul>
</div></details><h2 id="reexports" class="section-header">Re-exports<a href="#reexports" class="anchor">§</a></h2><dl class="item-table reexports"><dt id="reexport.CpuStorage"><code>pub use cpu_backend::<a class="enum" href="cpu_backend/enum.CpuStorage.html" title="enum candle_core::cpu_backend::CpuStorage">CpuStorage</a>;</code></dt><dt id="reexport.CpuStorageRef"><code>pub use cpu_backend::<a class="enum" href="cpu_backend/enum.CpuStorageRef.html" title="enum candle_core::cpu_backend::CpuStorageRef">CpuStorageRef</a>;</code></dt><dt id="reexport.Context"><code>pub use error::<a class="trait" href="error/trait.Context.html" title="trait candle_core::error::Context">Context</a>;</code></dt><dt id="reexport.Error"><code>pub use error::<a class="enum" href="error/enum.Error.html" title="enum candle_core::error::Error">Error</a>;</code></dt><dt id="reexport.Result"><code>pub use error::<a class="type" href="error/type.Result.html" title="type candle_core::error::Result">Result</a>;</code></dt><dt id="reexport.Layout"><code>pub use layout::<a class="struct" href="layout/struct.Layout.html" title="struct candle_core::layout::Layout">Layout</a>;</code></dt><dt id="reexport.Shape"><code>pub use shape::<a class="struct" href="shape/struct.Shape.html" title="struct candle_core::shape::Shape">Shape</a>;</code></dt><dt id="reexport.D"><code>pub use shape::<a class="enum" href="shape/enum.D.html" title="enum candle_core::shape::D">D</a>;</code></dt><dt id="reexport.StreamTensor"><code>pub use streaming::<a class="struct" href="streaming/struct.StreamTensor.html" title="struct candle_core::streaming::StreamTensor">StreamTensor</a>;</code></dt><dt id="reexport.StreamingBinOp"><code>pub use streaming::<a class="struct" href="streaming/struct.StreamingBinOp.html" title="struct candle_core::streaming::StreamingBinOp">StreamingBinOp</a>;</code></dt><dt id="reexport.StreamingModule"><code>pub use streaming::<a class="trait" href="streaming/trait.StreamingModule.html" title="trait candle_core::streaming::StreamingModule">StreamingModule</a>;</code></dt><dt id="reexport.cuda"><code>pub use <a class="mod" href="dummy_cuda_backend/index.html" title="mod candle_core::dummy_cuda_backend">dummy_cuda_backend</a> as cuda;</code></dt><dt id="reexport.CudaDevice"><code>pub use cuda::<a class="struct" href="dummy_cuda_backend/struct.CudaDevice.html" title="struct candle_core::dummy_cuda_backend::CudaDevice">CudaDevice</a>;</code></dt><dt id="reexport.CudaStorage"><code>pub use cuda::<a class="struct" href="dummy_cuda_backend/struct.CudaStorage.html" title="struct candle_core::dummy_cuda_backend::CudaStorage">CudaStorage</a>;</code></dt><dt id="reexport.MetalDevice"><code>pub use metal_backend::<a class="struct" href="metal_backend/struct.MetalDevice.html" title="struct candle_core::metal_backend::MetalDevice">MetalDevice</a>;</code></dt><dt id="reexport.MetalError"><code>pub use metal_backend::<a class="enum" href="metal_backend/enum.MetalError.html" title="enum candle_core::metal_backend::MetalError">MetalError</a>;</code></dt><dt id="reexport.MetalStorage"><code>pub use metal_backend::<a class="struct" href="metal_backend/struct.MetalStorage.html" title="struct candle_core::metal_backend::MetalStorage">MetalStorage</a>;</code></dt></dl><h2 id="modules" class="section-header">Modules<a href="#modules" class="anchor">§</a></h2><dl class="item-table"><dt><a class="mod" href="backend/index.html" title="mod candle_core::backend">backend</a></dt><dd>Traits to Define Backend Behavior</dd><dt><a class="mod" href="backprop/index.html" title="mod candle_core::backprop">backprop</a></dt><dd>Methods for backpropagation of gradients.</dd><dt><a class="mod" href="conv/index.html" title="mod candle_core::conv">conv</a></dt><dd>1D and 2D Convolutions</dd><dt><a class="mod" href="cpu/index.html" title="mod candle_core::cpu">cpu</a></dt><dd>Traits and methods for CPU-backed Tensors</dd><dt><a class="mod" href="cpu_backend/index.html" title="mod candle_core::cpu_backend">cpu_<wbr>backend</a></dt><dd>Implementation of Backend Fns for CPU</dd><dt><a class="mod" href="display/index.html" title="mod candle_core::display">display</a></dt><dd>Pretty printing of tensors</dd><dt><a class="mod" href="dummy_cuda_backend/index.html" title="mod candle_core::dummy_cuda_backend">dummy_<wbr>cuda_<wbr>backend</a></dt><dd>Implementation of the Cuda backend when Cuda support has not been compiled in.</dd><dt><a class="mod" href="error/index.html" title="mod candle_core::error">error</a></dt><dd>Candle-specific Error and Result</dd><dt><a class="mod" href="layout/index.html" title="mod candle_core::layout">layout</a></dt><dd>Tensor Layouts including contiguous or sparse strides</dd><dt><a class="mod" href="metal_backend/index.html" title="mod candle_core::metal_backend">metal_<wbr>backend</a></dt><dd>Implementation of Backend traits for Metal</dd><dt><a class="mod" href="npy/index.html" title="mod candle_core::npy">npy</a></dt><dd>Numpy support for tensors.</dd><dt><a class="mod" href="op/index.html" title="mod candle_core::op">op</a></dt><dd>Tensor Opertion Enums and Traits</dd><dt><a class="mod" href="pickle/index.html" title="mod candle_core::pickle">pickle</a></dt><dd>Just enough pickle support to be able to read PyTorch checkpoints.</dd><dt><a class="mod" href="quantized/index.html" title="mod candle_core::quantized">quantized</a></dt><dd>Code for GGML and GGUF files</dd><dt><a class="mod" href="safetensors/index.html" title="mod candle_core::safetensors">safetensors</a></dt><dd>Module to load <code>safetensor</code> files into CPU/GPU memory.</dd><dt><a class="mod" href="scalar/index.html" title="mod candle_core::scalar">scalar</a></dt><dd>TensorScalar Enum and Trait</dd><dt><a class="mod" href="shape/index.html" title="mod candle_core::shape">shape</a></dt><dd>The shape of a tensor is a tuple with the size of each of its dimensions.</dd><dt><a class="mod" href="streaming/index.html" title="mod candle_core::streaming">streaming</a></dt><dd>StreamTensror useful for streaming ops.</dd><dt><a class="mod" href="test_utils/index.html" title="mod candle_core::test_utils">test_<wbr>utils</a></dt><dt><a class="mod" href="utils/index.html" title="mod candle_core::utils">utils</a></dt><dd>Useful functions for checking features.</dd></dl><h2 id="macros" class="section-header">Macros<a href="#macros" class="anchor">§</a></h2><dl class="item-table"><dt><a class="macro" href="macro.bail.html" title="macro candle_core::bail">bail</a></dt><dt><a class="macro" href="macro.map_dtype.html" title="macro candle_core::map_dtype">map_<wbr>dtype</a></dt><dt><a class="macro" href="macro.test_device.html" title="macro candle_core::test_device">test_<wbr>device</a></dt></dl><h2 id="structs" class="section-header">Structs<a href="#structs" class="anchor">§</a></h2><dl class="item-table"><dt><a class="struct" href="struct.DTypeParseError.html" title="struct candle_core::DTypeParseError">DType<wbr>Parse<wbr>Error</a></dt><dt><a class="struct" href="struct.StridedIndex.html" title="struct candle_core::StridedIndex">Strided<wbr>Index</a></dt><dd>An iterator over offset position for items of an N-dimensional arrays stored in a
flat buffer using some potential strides.</dd><dt><a class="struct" href="struct.Tensor.html" title="struct candle_core::Tensor">Tensor</a></dt><dd>The core struct for manipulating tensors.</dd><dt><a class="struct" href="struct.TensorId.html" title="struct candle_core::TensorId">Tensor<wbr>Id</a></dt><dd>Unique identifier for tensors.</dd><dt><a class="struct" href="struct.UgIOp1.html" title="struct candle_core::UgIOp1">UgIOp1</a></dt><dt><a class="struct" href="struct.Var.html" title="struct candle_core::Var">Var</a></dt><dd>A variable is a wrapper around a tensor, however variables can have their content modified
whereas tensors are immutable.</dd></dl><h2 id="enums" class="section-header">Enums<a href="#enums" class="anchor">§</a></h2><dl class="item-table"><dt><a class="enum" href="enum.DType.html" title="enum candle_core::DType">DType</a></dt><dd>The different types of elements allowed in tensors.</dd><dt><a class="enum" href="enum.Device.html" title="enum candle_core::Device">Device</a></dt><dd>Cpu, Cuda, or Metal</dd><dt><a class="enum" href="enum.DeviceLocation.html" title="enum candle_core::DeviceLocation">Device<wbr>Location</a></dt><dd>A <code>DeviceLocation</code> represents a physical device whereas multiple <code>Device</code>
can live on the same location (typically for cuda devices).</dd><dt><a class="enum" href="enum.Storage.html" title="enum candle_core::Storage">Storage</a></dt><dt><a class="enum" href="enum.StridedBlocks.html" title="enum candle_core::StridedBlocks">Strided<wbr>Blocks</a></dt><dt><a class="enum" href="enum.TensorIndexer.html" title="enum candle_core::TensorIndexer">Tensor<wbr>Indexer</a></dt><dd>Generic structure used to index a slice of the tensor</dd></dl><h2 id="traits" class="section-header">Traits<a href="#traits" class="anchor">§</a></h2><dl class="item-table"><dt><a class="trait" href="trait.CustomOp1.html" title="trait candle_core::CustomOp1">Custom<wbr>Op1</a></dt><dd>Unary ops that can be defined in user-land.</dd><dt><a class="trait" href="trait.CustomOp2.html" title="trait candle_core::CustomOp2">Custom<wbr>Op2</a></dt><dt><a class="trait" href="trait.CustomOp3.html" title="trait candle_core::CustomOp3">Custom<wbr>Op3</a></dt><dt><a class="trait" href="trait.FloatDType.html" title="trait candle_core::FloatDType">FloatD<wbr>Type</a></dt><dt><a class="trait" href="trait.IndexOp.html" title="trait candle_core::IndexOp">IndexOp</a></dt><dd>Trait used to implement multiple signatures for ease of use of the slicing
of a tensor</dd><dt><a class="trait" href="trait.InplaceOp1.html" title="trait candle_core::InplaceOp1">Inplace<wbr>Op1</a></dt><dd>Unary ops that can be defined in user-land.
These ops work in place and as such back-prop is unsupported.</dd><dt><a class="trait" href="trait.InplaceOp2.html" title="trait candle_core::InplaceOp2">Inplace<wbr>Op2</a></dt><dt><a class="trait" href="trait.InplaceOp3.html" title="trait candle_core::InplaceOp3">Inplace<wbr>Op3</a></dt><dt><a class="trait" href="trait.IntDType.html" title="trait candle_core::IntDType">IntD<wbr>Type</a></dt><dt><a class="trait" href="trait.Module.html" title="trait candle_core::Module">Module</a></dt><dd>Defining a module with forward method using a single argument.</dd><dt><a class="trait" href="trait.ModuleT.html" title="trait candle_core::ModuleT">ModuleT</a></dt><dd>A single forward method using a single single tensor argument and a flag to
separate the training and evaluation behaviors.</dd><dt><a class="trait" href="trait.NdArray.html" title="trait candle_core::NdArray">NdArray</a></dt><dt><a class="trait" href="trait.ToUsize2.html" title="trait candle_core::ToUsize2">ToUsize2</a></dt><dt><a class="trait" href="trait.WithDType.html" title="trait candle_core::WithDType">WithD<wbr>Type</a></dt></dl></section></div></main></body></html>