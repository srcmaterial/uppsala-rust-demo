searchState.loadedDescShard("rbert", 0, "rbert\nA bert embedding model. The main interface for this model …\nA builder for a <code>Bert</code> model\nAn error that can occur when running a Bert model.\nAn error that can occur when loading a Bert model.\nA raw synchronous Bert model. You should generally use the …\nA the source of a <code>crate::Bert</code> model\nTake the embedding of the CLS token for each sequence\nAn error that can occur when trying to run a Bert model.\nThe configuration of a <code>BertModel</code>.\nA config was not found\nThe model should output an embedding for documents.\nAn error that can occur when trying to load a Bert model …\nA model that can be used to embed text. This trait is …\nAn extension trait for <code>Embedder</code> that allows for caching …\nAn extension trait for <code>Embedder</code> with helper methods for …\nEmbeddings\nThe input to an embedding model. This includes the text to …\nThe type of embedding the model should output. For models …\nThe error type that can occur when embedding a string.\nAn error that can occur when creating the model.\nFailed to join the thread that is running the model\nAn error that can occur when trying to load the bert …\nAn error that can occur when trying to load a Bert model.\nAn error that can occur when trying to load the bert …\nTake the mean embedding value for all tokens (except …\nThe model that this trait creates.\nA builder that can create a model asynchronously.\nThe pooling strategy to use when embedding text.\nThe model should output an embedding for a query.\nAn error that can occur when tokenizing or detokenizing …\nCreate a new <code>BertSource</code> with the BGE base english preset\nCreate a new <code>BertSource</code> with the BGE large english preset\nCreate a new <code>BertSource</code> with the BGE small english preset\nBuild the model\nBuild the model with a loading handler\nCreate a new <code>BertBuilder</code>\nWrap the embedder with a cache for previously computed …\nWrap the embedder with a cache for previously computed …\nCompute the cosine similarity between this embedding and …\nEmbed some text into a vector space\nEmbed some text into a vector space\nEmbed a batch of text into a vector space. Returns a list …\nEmbed a batch of text into a vector space. Returns a list …\nEmbed a batch of <code>EmbeddingInput</code> into a vector space. …\nEmbed a batch of <code>EmbeddingInput</code> into a vector space. …\nEmbed a batch of sentences with a specific pooling …\nEmbed a <code>EmbeddingInput</code> into a vector space\nEmbed a query into a vector space\nEmbed a query into a vector space\nEmbed some text into a vector space.\nEmbed some text into a vector space.\nEmbed a <code>Vec&lt;String&gt;</code> into a vector space. Returns a list of …\nEmbed a <code>Vec&lt;String&gt;</code> into a vector space. Returns a list of …\nEmbed a <code>Vec&lt;String&gt;</code> into a vector space. Returns a list of …\nEmbed a <code>Vec&lt;String&gt;</code> into a vector space. Returns a list of …\nEmbed a sentence with a specific pooling strategy.\nRun the bert model with a batch of inputs.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConvert this embedder into an embedder trait object.\nConvert this embedder into an embedder trait object.\nLoad a new <code>BertModel</code> from <code>VarBuilder</code> with a <code>Config</code>.\nCreate a new <code>BertSource</code> with the MiniLM-L6-v2 preset\nCreate a new embedding from a tensor.\nCreate a new <code>BertSource</code> for embedding plain text\nCreate a new default bert model\nCreate a new embedding input.\nCreate a new <code>BertSource</code> for embedding text for search\nCreate a new default bert model for search\nCheck if the model will need to be downloaded before use …\nCheck if the model will need to be downloaded before use …\nCreate a new <code>BertSource</code> with the snowflake-arctic-embed-xs …\nCreate a new <code>BertSource</code> with the snowflake-arctic-embed-l …\nCreate a new <code>BertSource</code> with the snowflake-arctic-embed-m …\nCreate a new <code>BertSource</code> with the …\nCreate a new <code>BertSource</code> with the snowflake-arctic-embed-s …\nStart the model.\nStart the model.\nStart the model with a loading handler.\nStart the model with a loading handler.\nThe text to embed.\nThe type of embedding to embed the text into.\nGet the tensor that represents this embedding.\nSet the cache location to use for the model (defaults …\nSet the config to use\nSet the model to use, check out available models: …\nSet the source of the model\nSet the tokenizer to use")