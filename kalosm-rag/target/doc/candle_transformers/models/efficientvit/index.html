<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="EfficientViT (MSRA) inference implementation based on timm."><title>candle_transformers::models::efficientvit - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../../static.files/rustdoc-916cea96.css"><meta name="rustdoc-vars" data-root-path="../../../" data-static-root-path="../../../static.files/" data-current-crate="candle_transformers" data-themes="" data-resource-suffix="" data-rustdoc-version="1.87.0 (17067e9ac 2025-05-09)" data-channel="1.87.0" data-search-js="search-e7298875.js" data-settings-js="settings-d72f25bb.js" ><script src="../../../static.files/storage-82c7156e.js"></script><script defer src="../sidebar-items.js"></script><script defer src="../../../static.files/main-fb8c74a8.js"></script><noscript><link rel="stylesheet" href="../../../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../../../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../../../static.files/favicon-044be391.svg"></head><body class="rustdoc mod"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../../../candle_transformers/index.html">candle_<wbr>transformers</a><span class="version">0.8.4</span></h2></div><div class="sidebar-elems"><section id="rustdoc-toc"><h2 class="location"><a href="#">Module efficientvit</a></h2><h3><a href="#">Sections</a></h3><ul class="block top-toc"><li><a href="#example-usage" title="Example Usage">Example Usage</a></li></ul><h3><a href="#structs">Module Items</a></h3><ul class="block"><li><a href="#structs" title="Structs">Structs</a></li><li><a href="#functions" title="Functions">Functions</a></li></ul></section><div id="rustdoc-modnav"><h2><a href="../index.html">In candle_<wbr>transformers::<wbr>models</a></h2></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><div class="rustdoc-breadcrumbs"><a href="../../index.html">candle_transformers</a>::<wbr><a href="../index.html">models</a></div><h1>Module <span>efficientvit</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../../../src/candle_transformers/models/efficientvit.rs.html#1-490">Source</a> </span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>EfficientViT (MSRA) inference implementation based on timm.</p>
<p>This crate provides an implementation of the EfficientViT model from Microsoft Research Asia
for efficient image classification. The model uses cascaded group attention modules
to achieve strong performance while maintaining low memory usage.</p>
<p>The model was originally described in the paper:
<a href="https://arxiv.org/abs/2305.07027">“EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention”</a></p>
<p>This implementation is based on the reference implementation from
<a href="https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/efficientvit_msra.py">pytorch-image-models</a>.</p>
<h2 id="example-usage"><a class="doc-anchor" href="#example-usage">§</a>Example Usage</h2>
<p>This candle implementation uses a pre-trained EfficientViT (from Microsoft Research Asia) network for inference.
The classification head has been trained on the ImageNet dataset and returns the probabilities for the top-5 classes.</p>
<div class="example-wrap"><pre class="language-bash"><code>cargo run
  --example efficientvit \
  --release -- \
  --image candle-examples/examples/yolo-v8/assets/bike.jpg --which m1

&gt; loaded image Tensor[dims 3, 224, 224; f32]
&gt; model built
&gt; mountain bike, all-terrain bike, off-roader: 69.80%
&gt; unicycle, monocycle     : 13.03%
&gt; bicycle-built-for-two, tandem bicycle, tandem: 9.28%
&gt; crash helmet            : 2.25%
&gt; alp                     : 0.46%</code></pre></div><div align=center>
  <img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.jpg" alt="" width=640>
</div>
</div></details><h2 id="structs" class="section-header">Structs<a href="#structs" class="anchor">§</a></h2><dl class="item-table"><dt><a class="struct" href="struct.Config.html" title="struct candle_transformers::models::efficientvit::Config">Config</a></dt></dl><h2 id="functions" class="section-header">Functions<a href="#functions" class="anchor">§</a></h2><dl class="item-table"><dt><a class="fn" href="fn.efficientvit.html" title="fn candle_transformers::models::efficientvit::efficientvit">efficientvit</a></dt><dt><a class="fn" href="fn.efficientvit_no_final_layer.html" title="fn candle_transformers::models::efficientvit::efficientvit_no_final_layer">efficientvit_<wbr>no_<wbr>final_<wbr>layer</a></dt></dl></section></div></main></body></html>